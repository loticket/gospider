# Gospider
[![codecov](https://codecov.io/gh/zhshch2002/gospider/branch/master/graph/badge.svg)](https://codecov.io/gh/zhshch2002/gospider)

è½»é‡çš„ Golang çˆ¬è™«æ¡†æž¶ã€‚[Github](https://github.com/zhshch2002/gospider)

## ðŸš€Feature
* ä¼˜é›…çš„ API
* æ•´æ´çš„æ–‡æ¡£
* é«˜é€Ÿï¼ˆå•æ ¸å¤„ç† >1K task/secï¼‰
* å‹å–„çš„åˆ†å¸ƒå¼æ”¯æŒ
* ä¸€äº›ç»†èŠ‚
  * ç›¸å¯¹é“¾æŽ¥è‡ªåŠ¨è½¬æ¢
  * å­—ç¬¦ç¼–ç è‡ªåŠ¨è§£ç 
  * HTML,JSON è‡ªåŠ¨è§£æž
* ä¸°å¯Œçš„æ‰©å±•æ”¯æŒ
  * è‡ªåŠ¨åŽ»é‡
  * å¤±è´¥é‡è¯•
  * è®°å½•å¼‚å¸¸è¯·æ±‚
  * æŽ§åˆ¶å»¶æ—¶ã€éšæœºå»¶æ—¶ã€å¹¶å‘ã€é€ŸçŽ‡
  * Robots.txt æ”¯æŒ
  * éšæœº UA
* è½»é‡ï¼Œé€‚äºŽå­¦ä¹ æˆ–å¿«é€Ÿå¼€ç®±æ­å»º

## ðŸ‘œèŽ·å– Goribot
```sh
go get -u github.com/zhshch2002/gospider
```

Gospider ä»Ž [Goribot](https://github.com/zhshch2002/goribot) æ”¹è¿›è€Œæ¥ï¼Œè§£å†³äº†é˜Ÿåˆ—ä»»åŠ¡ä¸¢å¤±ç­‰é—®é¢˜ï¼Œå¯ä»¥å‚è€ƒåŽŸé¡¹ç›®çš„ä¸€äº›æ–‡æ¡£ã€‚

Gospider å°†ç½‘ç»œè¯·æ±‚éƒ¨åˆ†ç§»åŠ¨åˆ° [Goreq|https://github.com/zhshch2002/goreq](https://github.com/zhshch2002/goribot) å•ç‹¬ç®¡ç†ã€‚

## âš¡å»ºç«‹ä½ çš„ç¬¬ä¸€ä¸ªé¡¹ç›®
```go
package main

import (
	"github.com/zhshch2002/goreq"
	"github.com/zhshch2002/gospider"
)

func main() {
    s := gospider.NewSpider() // åˆ›å»ºèœ˜è››

    s.SeedTask( // ç§å­ä»»åŠ¡
        goreq.Get("https://httpbin.org/get"),
        func(ctx *gospider.Context) {
            ctx.AddItem(ctx.Resp.Text) // æäº¤ä»»åŠ¡çˆ¬å–ç»“æžœ
        },
    )
    s.OnItem(func(ctx *gospider.Context, i interface{}) interface{} { // æ”¶é›†å¹¶å­˜å‚¨ç»“æžœ
        ctx.Println(i)
        return i
    })

    s.Wait() // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆå¹¶é‡Šæ”¾èµ„æº
}
```

## ä»Ž Colly äº†è§£ Gospider
```go
package main

import (
	"github.com/PuerkitoBio/goquery"
	"github.com/zhshch2002/goreq"
	"github.com/zhshch2002/gospider"
)

/* colly example http://go-colly.org/docs/examples/basic/

// Instantiate default collector
c := colly.NewCollector(
	// Visit only domains: hackerspaces.org, wiki.hackerspaces.org
	colly.AllowedDomains("hackerspaces.org", "wiki.hackerspaces.org"),
)

// On every a element which has href attribute call callback
c.OnHTML("a[href]", func(e *colly.HTMLElement) {
	link := e.Attr("href")
	// Print link
	fmt.Printf("Link found: %q -> %s\n", e.Text, link)
	// Visit link found on page
	// Only those links are visited which are in AllowedDomains
	c.Visit(e.Request.AbsoluteURL(link))
})

// Before making a request print "Visiting ..."
c.OnRequest(func(r *colly.Request) {
	fmt.Println("Visiting", r.URL.String())
})

// Start scraping on https://hackerspaces.org
c.Visit("https://hackerspaces.org/")
*/
func main() {
	s := gospider.NewSpider(goreq.WithFilterLimiter(false, &goreq.FilterLimiterOpinion{
		LimiterMatcher: goreq.LimiterMatcher{Glob: "*.hackerspaces.org"},
		Allow:          true,
	}, &goreq.FilterLimiterOpinion{
		LimiterMatcher: goreq.LimiterMatcher{Glob: "hackerspaces.org"},
		Allow:          true,
	}))

	// On every a element which has href attribute call callback
	s.OnHTML("a[href]", func(ctx *gospider.Context, sel *goquery.Selection) {
		link, _ := sel.Attr("href")
		// Print link
		ctx.Printf("Link found: %q -> %s\n", sel.Text(), link)
		// Visit link found on page
		// Only those links are visited which are in AllowedDomains
		ctx.AddTask(goreq.Get(link)) // gospider will auto convert to absolute URL
	})

	s.SeedTask(goreq.Get("https://hackerspaces.org/"))
	s.Wait()
}
```